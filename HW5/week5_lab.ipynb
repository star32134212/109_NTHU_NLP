{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPES <span style='font-size:20px'>: Majority Parentheses Expression by Sister pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "from nltk import word_tokenize\n",
    "from math import log, sqrt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load page_category\n",
    "`Format example`\n",
    "```python\n",
    "page_category = {\n",
    "    'Bass (fish)' : ['Category:Fish common names'],\n",
    "    'Star (automobile)' : ['Category:Defunct motor vehicle manufacturers of the United States', 'Category:Durant Motors'],\n",
    "    ...\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('page-to-cats.json') as f:\n",
    "    page_category = json.load(f)\n",
    "\n",
    "print(page_category['Bass (fish)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Count the classes of categories\n",
    "For each category, count the appearance of words(possible classes) in the title of the pages under it\n",
    "- you may use **`page_to_class()`**\n",
    "\n",
    "example:\n",
    "```python\n",
    "category_class_count['Category:Fish common names']['fish'] = 16\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the appearance of possible classes in the page title\n",
    "def page_to_class(page):\n",
    "    class_list = []\n",
    "    if '(' in page and 'disambiguation' not in page:\n",
    "        class_list.append(page.split('(')[1][:-1])\n",
    "    return class_list\n",
    "\n",
    "\n",
    "    print(page_to_class('Bass (fish)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_class_count = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "for page, category_list in page_category.items():\n",
    "    for page_class in page_to_class(page):\n",
    "        for category in category_list:\n",
    "            ##### YOUR CODE HERE #####\n",
    "            \n",
    "            \n",
    "category_class_count['Category:Fish common names']['fish']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentences.json') as f:\n",
    "    sentences = json.load(f)\n",
    "    \n",
    "    \n",
    "sentences['bass']['Bass (fish)'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Decide class of wikipedia pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each page in **sentences.json**, sum up the count of classes of all the categories it belongs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example:\n",
    "```python\n",
    "page_class_count['Bass (fish)'] = \n",
    "    {\n",
    "        ...,\n",
    "        'mackerel': 2,\n",
    "        'bass': 2,\n",
    "        'fish': 16,\n",
    "        'hake': 1,\n",
    "        'sea': 1,\n",
    "        ...\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_class_count = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "for page_list in sentences.values():\n",
    "    for page in page_list:\n",
    "        for category in page_category[page]:\n",
    "            for c, count in category_class_count[category].items():\n",
    "                ##### YOUR CODE HERE #####\n",
    "\n",
    "                \n",
    "page_class_count['Bass (fish)']['fish']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then, for each page, choose the class with the maximum count.\n",
    "\n",
    "example:\n",
    "```python\n",
    "page_class['Bass (fish)'] = 'fish'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_class = defaultdict(dict)\n",
    "\n",
    "for page, class_counts in page_class_count.items():\n",
    "    ##### YOUR CODE HERE #####\n",
    "    \n",
    "\n",
    "page_class['Bass (fish)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Combine sentences which have the same class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- construct __class_sents__ using __page_class__ & __sentences__ dictionaries\n",
    "\n",
    "`Format`\n",
    "```python\n",
    "class_sents = {\n",
    "    word: {\n",
    "        Class: {\n",
    "            [ sent_1, sent_2, ... ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "```\n",
    "`Examples`\n",
    "\n",
    "```python\n",
    "1.\n",
    "list(class_sents.keys())\n",
    "['star',\n",
    " 'mole',\n",
    " 'galley',\n",
    " 'cone',\n",
    " 'bass',\n",
    " 'bow',\n",
    " 'taste',\n",
    " 'interest',\n",
    " 'issue',\n",
    " 'duty',\n",
    " 'sentence',\n",
    " 'slug']\n",
    "\n",
    "2. \n",
    "list(class_sents['bass'].keys())\n",
    "['fish', 'music', 'sound']\n",
    "\n",
    "3.\n",
    "len(class_sents['bass']['fish']) = 668\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_sents = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for word, v in sentences.items():\n",
    "    for page, sents in v.items():\n",
    "        ##### YOUR CODE HERE #####\n",
    "\n",
    "\n",
    "print(list(class_sents['bass'].keys()))\n",
    "print(len(class_sents['bass']['fish']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Method - Yarowsky92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ weight_{ijk} = log(\\frac{Pr(w_i|Class_j)}{Pr(w_i|word_k)})$\n",
    "<br><br>\n",
    "where<br> \n",
    "$Pr(w_i|Class_j) = \\frac{Counts\\;of\\;w_i\\;in\\;Class_j}{Counts\\;of\\;all\\;words\\;in\\;Class_j}$<br><br>\n",
    "$Pr(w_i|word_k) = \\frac{Counts\\;of\\;w_i\\;in\\;word_k}{Counts\\;of\\;all\\;words\\;in\\;word_k}$\n",
    "<br><br>\n",
    "\n",
    "\n",
    "`Instruction`\n",
    "\n",
    "Step 1. For each $word_k$, tokenize every sentences and count all words in $word_k$ as N<br>\n",
    "Step 2. For each $class_j$, count all words in $class_j$ as n<br>\n",
    "Step 3. For each word $w_i$, count occurances in $class_j$ and $word_k$, repectively.<br>\n",
    "Step 4. Calculate $weight_{ijk}$\n",
    "\n",
    "\n",
    "`Example`\n",
    "```python\n",
    "weight['bass']['fish']['freshwater'] = 3.0273651127101293\n",
    "max(weight['bass']['fish'].items(), key = lambda x: x[1]) = ('bream', 3.1972901141524415)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0.0)))\n",
    "\n",
    "for word, v in class_sents.items():\n",
    "    total_words = {}\n",
    "    for wiki_class, sents in v.items():\n",
    "        total_words[wiki_class] = Counter([word.lower() for sent in sents for word in word_tokenize(sent)])\n",
    "    N = ? ##### Finish it #####\n",
    "    for wiki_class, sents in v.items():\n",
    "        n = ? ##### Finish it #####\n",
    "        for tks in total_words[wiki_class]:\n",
    "            ##### YOUR CODE HERE #####\n",
    "\n",
    "            \n",
    "print(weight['bass']['fish']['freshwater'])\n",
    "print(max(weight['bass']['fish'].items(), key = lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify sentence with max weight \n",
    "\n",
    "$ score = \\sum\\limits_{w\\in context}weight_w $\n",
    "\n",
    "`Example`\n",
    "```python\n",
    "most_similar('bass', 'Bass, catfish, and bluegill also inhabit the creek.') \n",
    "    = (\"fish\", 14.814981643783032)\n",
    "\n",
    "most_similar('issue', 'He\\'s contributed to several publications, including LA Review of Books, Purple, Issue, and Hesperios Journal.') \n",
    "    = (\"magazine\", 5.123843862532843)\n",
    "\n",
    "most_similar('sentence', 'If it finds the accused guilty, it passes sentence on the accused according to law.') \n",
    "    = (\"law\", 5.77941354006321)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word, query):\n",
    "    max_class, max_value = ('', np.NINF)\n",
    "    q_tokens = word_tokenize(query)\n",
    "    ##### YOUR CODE HERE #####\n",
    "    \n",
    "    \n",
    "    return (max_class, max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [['bass', 'fish', 'Bass, catfish, and bluegill also inhabit the creek.'],\n",
    "             ['issue', 'magazine', 'He\\'s contributed to several publications, including LA Review of Books, Purple, Issue, and Hesperios Journal.'],\n",
    "             ['sentence', 'law', 'If it finds the accused guilty, it passes sentence on the accused according to law.']]\n",
    "\n",
    "# Pass the test to get 100 points\n",
    "for (word, wiki_class, query) in test_data:\n",
    "    print('Predict class: %s (%s)'%most_similar(word, query))\n",
    "    print('Correct class: %s\\n'%wiki_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bouns - Classification 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Method - tf-idf weights\n",
    "\n",
    "\n",
    "`term frequency`<br><br>$f_{i,j}$\n",
    "<br>\n",
    "\n",
    "`log normalization term frequency weight`<br><br>\n",
    "$ 1 + log_2 f_{i,j} $,\n",
    "<br>\n",
    "\n",
    "where $f_{i,j}$ is times term i occur in document j, <br>\n",
    "(One document is one class in there)\n",
    "<br><br>\n",
    "`inverse document frequency`<br><br>\n",
    "$ log_2( \\frac{N}{n_i}) $,\n",
    "\n",
    "where $N$ is number of documents, <br>\n",
    "and $n_i$ is times of term i occur in documents\n",
    "<br><br>\n",
    "`Examples`\n",
    "```Python\n",
    "term_doc_tf['star']['film']['role'] = 2.584962500721156\n",
    "\n",
    "term_idf['star']['role'] = 1.5849625007211563\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "1. calculate log normalization term frequency weight (term_doc_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_doc_tf = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0.0)))\n",
    "\n",
    "for word, v in class_sents.items():\n",
    "    for classes, sents in v.items():\n",
    "        tokens = Counter([tks for sent in list(map(word_tokenize, list(map(str.lower, sents)))) for tks in sent])\n",
    "        for tok in tokens:\n",
    "            if tok not in term_doc_tf[word][classes]:\n",
    "                ##### YOUR CODE HERE #####\n",
    "\n",
    "\n",
    "print(term_doc_tf['star']['film']['role'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. calculate inverse document frequency (term_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_idf = defaultdict(lambda:defaultdict(lambda: 0.0))\n",
    "\n",
    "for word, v in class_sents.items():\n",
    "    sents_tokens = [Counter([sub_s for s in list(map(word_tokenize,list(map(str.lower,sent)))) for sub_s in s]) for sent in v.values()]\n",
    "    N = len(sents_tokens)\n",
    "    for sent in sents_tokens:\n",
    "        for tok in sent:\n",
    "            ##### YOUR CODE HERE #####\n",
    "\n",
    "\n",
    "print(term_idf['star']['role'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term frequency of the query and similarity\n",
    "\n",
    "`Term frequency`<br><br>\n",
    "$ 1 + log_2 f_{i, q} $\n",
    "\n",
    "<br>\n",
    "\n",
    "`Similarity`<br><br>\n",
    "$ sim(d_j, q) = \\frac{\\Sigma^t_{i=1} w_{i,j} \\times w_{i,q}}{ \\sqrt{\\Sigma^t_{i=1} w_{i,j}^2} \\times \\sqrt{\\Sigma^t_{i=1} w_{i,q}^2}} $\n",
    "\n",
    "where $w_{i,j} = (1 + log_2 f_{i,j}) \\times log_2( \\frac{N}{n_i})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find most similar class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_term_freq(query):\n",
    "    query_tf = defaultdict(lambda: 0.0)\n",
    "    tokens = word_tokenize(query.lower())\n",
    "    for tok in tokens:\n",
    "        if tok.lower() not in query_tf:\n",
    "            query_tf[tok] = (1 + log(tokens.count(tok), 2))\n",
    "    return query_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar(word, query):\n",
    "    query_tf = query_term_freq(query)\n",
    "    max_class, max_value = ('', np.NINF)\n",
    "    for candid, terms in term_doc_tf[word].items():\n",
    "        ##### YOUR CODE HERE #####\n",
    "        \n",
    "\n",
    "    return (max_class, max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please pass the test\n",
    "for (word, classes, query) in test_data:\n",
    "    print('Predict class: %s (%s)'%find_most_similar(word, query))\n",
    "    print('Correct class: %s\\n'%classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
