{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#read-data\" data-toc-modified-id=\"read-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>read data</a></span></li><li><span><a href=\"#sentence-processing\" data-toc-modified-id=\"sentence-processing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>sentence processing</a></span></li><li><span><a href=\"#[Step-1]-generate-all-the-skip-bigram-of-&quot;edit-tag&quot;\" data-toc-modified-id=\"[Step-1]-generate-all-the-skip-bigram-of-&quot;edit-tag&quot;-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>[Step 1] generate all the skip-bigram of \"edit tag\"</a></span></li><li><span><a href=\"#set-POS-rules\" data-toc-modified-id=\"set-POS-rules-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>set POS rules</a></span></li><li><span><a href=\"#set-progress\" data-toc-modified-id=\"set-progress-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>set progress</a></span></li><li><span><a href=\"#[Step-2]-implement-skip-bigram\" data-toc-modified-id=\"[Step-2]-implement-skip-bigram-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>[Step 2] implement skip bigram</a></span></li><li><span><a href=\"#[Step-3]-calculate-all-the-required-number-first-(freq,-std,-spread,-etc.)\" data-toc-modified-id=\"[Step-3]-calculate-all-the-required-number-first-(freq,-std,-spread,-etc.)-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>[Step 3] calculate all the required number first (freq, std, spread, etc.)</a></span></li><li><span><a href=\"#[Step-4]-implement-Smadja-algorithm\" data-toc-modified-id=\"[Step-4]-implement-Smadja-algorithm-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>[Step 4] implement Smadja algorithm</a></span></li><li><span><a href=\"#[Level-C]-Collocation-Correction\" data-toc-modified-id=\"[Level-C]-Collocation-Correction-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>[Level C] Collocation Correction</a></span><ul class=\"toc-item\"><li><span><a href=\"#generate-the-collocation-candidate\" data-toc-modified-id=\"generate-the-collocation-candidate-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>generate the collocation candidate</a></span></li><li><span><a href=\"#call-linggle-api-to-calculate-candidates-count\" data-toc-modified-id=\"call-linggle-api-to-calculate-candidates-count-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>call linggle api to calculate candidates count</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math, nltk, re\n",
    "from collections import defaultdict\n",
    "from math import sqrt\n",
    "import operator\n",
    "import json\n",
    "import sys\n",
    "import threading\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S The//DET making//VERB souvenir//NOUN is//AUX a//DET hard//ADJ and//CCONJ interesting//ADJ work//NOUN .//PUNCT',\n",
       " 'A 0 2|||U:DET|||Making|||REQUIRED|||-NONE-|||0',\n",
       " 'A 2 3|||R:NOUN:NUM|||souvenirs|||REQUIRED|||-NONE-|||0',\n",
       " 'A 6 7|||R:CONJ|||but|||REQUIRED|||-NONE-|||0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# M:insert U:delete R:replace\n",
    "PROBLEM_WORDS = [ line.strip() for line in open('problem_word_list.txt') ]\n",
    "corpus = open('lang8.pos.m2.txt').read().split('\\n\\n')\n",
    "corpus_list = [i.split('\\n') for i in corpus]\n",
    "corpus_list = [i for i in corpus_list if len(i) >=2]\n",
    "\n",
    "corpus_list[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentence processing\n",
    "Input :\n",
    "``` python\n",
    "sentence = 'S I//PRON feel//VERB relax//VERB to//PART take//VERB a//DET bedrock//NOUN bath//NOUN ^//PUNCT ^//PUNCT'\n",
    "edit = 'A 1 2|||R:VERB:TENSE|||felt|||REQUIRED|||-NONE-|||0'\n",
    "```\n",
    "\n",
    "Output :\n",
    "``` python\n",
    "['I//PRON',\n",
    " '[-feel//R:VERB:TENSE-]{+felt//R:VERB:TENSE+}',\n",
    " 'relax//VERB',\n",
    " 'to//PART',\n",
    " 'take//VERB',\n",
    " 'a//DET',\n",
    " 'bedrock//NOUN',\n",
    " 'bath//NOUN',\n",
    " '^//PUNCT',\n",
    " '^//PUNCT']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m2_to_wikiedit(sentence, edit):\n",
    "    sent = [i for i in sentence.split()[1:]]\n",
    "    index, pos, word, _, _, _ = edit.split('|||')\n",
    "    start, end = [int(i) for i in index.split()[1:] ]\n",
    "    if pos[0] == 'M': \n",
    "        sent.insert(start, '{+' + '_'.join(word.split()) + '//'+ pos + '+}')\n",
    "    elif pos[0] == 'U':\n",
    "        _del = '_'.join([sent[i].split('//')[0] for i in range(start, end)])\n",
    "        del sent[start:end]\n",
    "        sent.insert(start, '[-' + _del + '//'+ pos + '-]' )\n",
    "    else:\n",
    "        _rep = '_'.join([sent[i].split('//')[0] for i in range(start, end)])\n",
    "        del sent[start:end]\n",
    "        sent.insert(start, '[-' + _rep + '//'+ pos + '-]{+' + '_'.join(word.split()) + '//'+ pos + '+}' )\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I//PRON',\n",
       " '[-feel//R:VERB:TENSE-]{+felt//R:VERB:TENSE+}',\n",
       " 'relax//VERB',\n",
       " 'to//PART',\n",
       " 'take//VERB',\n",
       " 'a//DET',\n",
       " 'bedrock//NOUN',\n",
       " 'bath//NOUN',\n",
       " '^//PUNCT',\n",
       " '^//PUNCT']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'S I//PRON feel//VERB relax//VERB to//PART take//VERB a//DET bedrock//NOUN bath//NOUN ^//PUNCT ^//PUNCT'\n",
    "edit = 'A 1 2|||R:VERB:TENSE|||felt|||REQUIRED|||-NONE-|||0'\n",
    "m2_to_wikiedit(sentence, edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Step 1] generate all the skip-bigram of \"edit tag\"\n",
    "* call m2_to_wikiedit function to process sentence\n",
    "* generate skip-bigram\n",
    "\n",
    "Example :\n",
    "``` python\n",
    "row = ['S I//PRON feel//VERB relax//VERB to//PART take//VERB a//DET bedrock//NOUN bath//NOUN ^//PUNCT ^//PUNCT',\n",
    " 'A 1 2|||R:VERB:TENSE|||felt|||REQUIRED|||-NONE-|||0',\n",
    " 'A 2 3|||R:ADJ:FORM|||relaxed|||REQUIRED|||-NONE-|||0']\n",
    "print(list_to_skipgram(row))\n",
    "```\n",
    "Result :  `[(problem_word, edit_tag, distance), ...]`\n",
    "``` python\n",
    "[('relax//VERB', '[-feel//R:VERB:TENSE-]{+felt//R:VERB:TENSE+}', -1),\n",
    " ('to//PART', '[-feel//R:VERB:TENSE-]{+felt//R:VERB:TENSE+}', -2),\n",
    " ('feel//VERB', '[-relax//R:ADJ:FORM-]{+relaxed//R:ADJ:FORM+}', 1),\n",
    " ('to//PART', '[-relax//R:ADJ:FORM-]{+relaxed//R:ADJ:FORM+}', -1)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_skipgram(row, maxdist=5, problem_words=PROBLEM_WORDS):\n",
    "    skip = []\n",
    "    ### Your code here ###\n",
    "    return skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('relax//VERB', '[-feel//R:VERB:TENSE-]{+felt//R:VERB:TENSE+}', 1), ('to//PART', '[-feel//R:VERB:TENSE-]{+felt//R:VERB:TENSE+}', 2), ('feel//VERB', '[-relax//R:ADJ:FORM-]{+relaxed//R:ADJ:FORM+}', -1), ('to//PART', '[-relax//R:ADJ:FORM-]{+relaxed//R:ADJ:FORM+}', 1)]\n"
     ]
    }
   ],
   "source": [
    "row = ['S I//PRON feel//VERB relax//VERB to//PART take//VERB a//DET bedrock//NOUN bath//NOUN ^//PUNCT ^//PUNCT',\n",
    " 'A 1 2|||R:VERB:TENSE|||felt|||REQUIRED|||-NONE-|||0',\n",
    " 'A 2 3|||R:ADJ:FORM|||relaxed|||REQUIRED|||-NONE-|||0']\n",
    "print(list_to_skipgram(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set POS rules\n",
    "Example :\n",
    "``` python\n",
    "print(rules['VERB']['R:PREP'].items())\n",
    "```\n",
    "Result :\n",
    "``` python\n",
    "dict_items([(-1, 59), (-3, 8), (-2, 10), (1, 3), (-4, 3)])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0)))\n",
    "\n",
    "with open('longman_count.tsv') as f:\n",
    "    datas = csv.DictReader(f, delimiter='\\t')\n",
    "    for data in datas:\n",
    "        if abs(int(data['Distance'])) < 5 and int(data['Distance']) != 0:\n",
    "            rules[data['Problem_Word_POS']][data['Edit_TYPE']][int(data['Distance'])] = data['Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(-1, '59'), (-2, '10'), (-3, '8'), (1, '3'), (-4, '3')])\n"
     ]
    }
   ],
   "source": [
    "print(rules['VERB']['R:PREP'].items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set progress\n",
    "設定progress，用來顯示程式執行進度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setInterval(interval, times = -1):\n",
    "    def outer_wrap(function):\n",
    "        # This will be the function to be\n",
    "        # called\n",
    "        def wrap(*args, **kwargs):\n",
    "            stop = threading.Event()\n",
    "            def inner_wrap():\n",
    "                i = 0\n",
    "                while i != times and not stop.isSet():\n",
    "                    stop.wait(interval)\n",
    "                    function(*args, **kwargs)\n",
    "                    i += 1\n",
    "            t = threading.Timer(0, inner_wrap)\n",
    "            t.daemon = True\n",
    "            t.start()\n",
    "            return stop\n",
    "        return wrap\n",
    "    return outer_wrap\n",
    "\n",
    "@setInterval(0.4)\n",
    "def progress():\n",
    "    sys.stdout.write('\\r%s%%'%int((index / len(corpus_list)) * 100 + 1))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Step 2] implement skip bigram\n",
    "Example :\n",
    "``` python\n",
    "print(skgm['arrive//VERB']['{+at//M:PREP+}'].items())\n",
    "```\n",
    "Result :\n",
    "``` python\n",
    "dict_items([(-1, 24), (2, 1)])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%"
     ]
    }
   ],
   "source": [
    "skgm = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0)))\n",
    " \n",
    "stopper = progress()\n",
    "\n",
    "for index, c in enumerate(corpus_list):\n",
    "    for pro, tag, dis in list_to_skipgram(c):\n",
    "        ### Your code here ###\n",
    "    \n",
    "stopper.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(-1, 24), (2, 1)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skgm['arrive//VERB']['{+at//M:PREP+}'].items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Step 3] calculate all the required number first (freq, std, spread, etc.)\n",
    "Example :\n",
    "\n",
    "``` python\n",
    "print(skipbigram_static['arrive//VERB']['{+at//M:PREP+}'])\n",
    "```\n",
    "Result :\n",
    "``` python\n",
    "{\n",
    "    'freq': 25,\n",
    "    'avg_p': 2.5,\n",
    "    'spread': 46.45,\n",
    "    'strength': 10.902214198919484,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/ipython/7.8.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "skipbigram_static = defaultdict(lambda: defaultdict())\n",
    "\n",
    "for pro, tag_list in skgm.items():\n",
    "    ### Your code here ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'freq': 25, 'avg_p': 2.5, 'spread': 46.45, 'strength': 10.90913905968529}\n"
     ]
    }
   ],
   "source": [
    "print(skipbigram_static['arrive//VERB']['{+at//M:PREP+}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Step 4] implement Smadja algorithm\n",
    "Example :\n",
    "\n",
    "``` python\n",
    "valid_collocation('discuss//VERB')\n",
    "print()\n",
    "valid_collocation('explain//VERB')\n",
    "```\n",
    "Result :\n",
    "``` python\n",
    "discuss//VERB [-about//U:PREP-] (-1, 11)\n",
    "\n",
    "explain//VERB [-about//U:PREP-] (-1, 19)\n",
    "explain//VERB {+to//M:PREP+} (-1, 12)\n",
    "explain//VERB {+it//M:PRON+} (-1, 17)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_collocation(key):\n",
    "    K0 = 1\n",
    "    U0 = 5\n",
    "    K1 = 1\n",
    "    collocation = []\n",
    "    for edit_tag in skipbigram_static[key]:\n",
    "        ### Your code here ###\n",
    "    return collocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('explain//VERB', '[-about//U:PREP-]', -1, 19),\n",
       " ('explain//VERB', '{+to//M:PREP+}', -1, 12),\n",
       " ('explain//VERB', '{+it//M:PRON+}', -1, 17)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_collocation('explain//VERB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Level C] Collocation Correction\n",
    "We'll use spacy to evaluate the word POS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "busy//ADJ\n",
      "in//ADP\n",
      "something//PRON\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "# ngram = 'discuss about the issue'\n",
    "# ngram = 'explain him'\n",
    "# ngram = 'talk me'\n",
    "ngram = 'busy in something'\n",
    "collocation = []\n",
    "for token in nlp(ngram):\n",
    "    print(token.text + '//' + token.pos_)\n",
    "    collocation.append(valid_collocation(token.text + '//' + token.pos_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate the collocation candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = []\n",
    "for i, rules in enumerate(collocation):\n",
    "    ### Your code here ###\n",
    "candidate.append(ngram.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['busy', 'with', 'something'],\n",
       " ['busy', 'my', 'in', 'something'],\n",
       " ['busy', 'something'],\n",
       " ['busy', 'in', 'a', 'something'],\n",
       " ['busy', 'in', 'the', 'something'],\n",
       " ['busy', 'now', 'in', 'something'],\n",
       " ['busy', 'in', 'my', 'something'],\n",
       " ['busy', 'in', 'an', 'something'],\n",
       " ['busy', 'in', 'our', 'something'],\n",
       " ['busy', 'in', 'this', 'something'],\n",
       " ['busy', 'in', 'to', 'something'],\n",
       " ['busy', 'in', 'their', 'something'],\n",
       " ['busy', 'in', 'something']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## call linggle api to calculate candidates count\n",
    "how to use linggle api:\n",
    "\n",
    "call:\n",
    "``` python\n",
    "result = ling.search('busy with something')\n",
    "print(result)\n",
    "```\n",
    "print:\n",
    "``` python\n",
    "# ['sentence', count]\n",
    "[['busy with something', 6420]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linggle_api_new import Linggle\n",
    "import pandas as pd\n",
    "\n",
    "ling = Linggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                result  count\n",
      "0  busy with something   6420\n",
      "1       busy something     67\n",
      "2    busy in something     52\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for cand in candidates:\n",
    "    ### Your code here ###\n",
    "\n",
    "print(pd.DataFrame(sorted(result, key = lambda x: -x[1]), columns = [\"result\", \"count\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
